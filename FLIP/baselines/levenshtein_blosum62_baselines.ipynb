{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1facb144-cacf-486a-a7f5-1127c2d18c5d",
   "metadata": {},
   "source": [
    "Test to see how well the Levenshtein distance can be used as a predictor for relevant datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d74569a-b4e6-4315-a66c-b5aa4e1b5b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Lxc/.conda/envs/bio-benchmarks/lib/python3.9/site-packages/Bio/SubsMat/__init__.py:126: BiopythonDeprecationWarning: Bio.SubsMat has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.substitution_matrices as a replacement, and contact the Biopython developers if you still need the Bio.SubsMat module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Bio import SeqIO\n",
    "from Bio.SubsMat.MatrixInfo import blosum62\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import ndcg_score\n",
    "import math\n",
    "\n",
    "# Create a new blosum matrix that has both directions. \n",
    "SYMMETRIC_BLOSUM = {}\n",
    "for (aa1, aa2), score in blosum62.items():\n",
    "    SYMMETRIC_BLOSUM[(aa1, aa2)] = score\n",
    "    SYMMETRIC_BLOSUM[(aa2, aa1)] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54545b8b-5a4d-405e-a0f3-bdc0913d6bf3",
   "metadata": {},
   "source": [
    "# General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed3b6c5-fb1f-47f8-8a4d-d790763b73d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_task(task_filename, reference_seq):\n",
    "    \n",
    "    # Load the task file and filter to just the test data\n",
    "    task_df = pd.read_csv(task_filename)\n",
    "    task_df = task_df.loc[task_df.set == \"test\"].copy()\n",
    "\n",
    "    # Create output arrays\n",
    "    refseq_len = len(reference_seq)\n",
    "    all_seqs = task_df.sequence.tolist()\n",
    "    levenshteins = np.empty(len(all_seqs))\n",
    "    blosum_scores = np.empty(len(all_seqs))\n",
    "    \n",
    "    # Calculate levenshtein distance between each sequence and the reference\n",
    "    levenshteins = np.array([levenshtein_distance(reference_seq, new_seq) \n",
    "                             for new_seq in task_df.sequence.values])\n",
    "    \n",
    "    # Calculate scores for each sequence    \n",
    "    calculate_blosum = True\n",
    "    for i, new_seq in enumerate(all_seqs):\n",
    "\n",
    "        # Score by levenshtein\n",
    "        levenshteins[i] = levenshtein_distance(reference_seq, new_seq)\n",
    "        \n",
    "        # Continue to calculate blosum unless the data is not aligned\n",
    "        if calculate_blosum:\n",
    "            \n",
    "            # Make sure the reference sequence and this sequence align\n",
    "            seqs_aligned = len(new_seq) == refseq_len\n",
    "            if not seqs_aligned:\n",
    "                print('seqs not aligned')\n",
    "                calculate_blosum = False\n",
    "                blosum_scores = None\n",
    "                continue\n",
    "            \n",
    "            # Calculate blosum scores\n",
    "            blosum_scores[i] = sum(SYMMETRIC_BLOSUM[(aa1, aa2)] for \n",
    "                                   aa1, aa2 in zip(reference_seq, new_seq))\n",
    "\n",
    "    # Now get spearman rho and record. Negative levenshtein because we\n",
    "    # expect a smaller distance to be correlated to larger fitness.\n",
    "    l_rho, _ = spearmanr(-levenshteins, task_df.target.values)\n",
    "    if blosum_scores is not None:\n",
    "        b_rho, _ = spearmanr(blosum_scores, task_df.target.values)\n",
    "        \n",
    "        \n",
    "        data = pd.DataFrame({'Predicted': blosum_scores, 'Labels': task_df.target.values})\n",
    "\n",
    "        directory, original_filename = os.path.split(task_filename)\n",
    "        filename = original_filename.split('_')[0] + '.csv'\n",
    "\n",
    "        data.to_csv(f'/home/Lxc/FLIP_results/BLOSUM62/{filename}')\n",
    "        k = math.floor(len(data['Predicted'])*0.01)\n",
    "        ndcg = ndcg_score([data['Labels'].values], [data['Predicted'].values],k=k)\n",
    "        print(round(ndcg, 2))\n",
    "        # 将数据保存到 CSV 文件\n",
    "        #data.to_csv('prediction.csv', index=False)\n",
    "    else:\n",
    "        b_rho = None\n",
    "    \n",
    "    return l_rho, b_rho\n",
    "\n",
    "def evaluate_tasks(refseq_fileloc, taskfolder, task_to_file_dict):\n",
    "    \n",
    "    # Get the reference sequence\n",
    "    reference_seq = str(next(SeqIO.parse(refseq_fileloc, \"fasta\")).seq)\n",
    "\n",
    "    # Loop over each task\n",
    "    results = [[\"Task\", \"Levenshtein Rho\", \"BLOSUM62 Rho\"]]\n",
    "    for taskname, taskfile in task_to_file_dict.items():\n",
    "        rhos = evaluate_task(os.path.join(taskfolder, taskfile), \n",
    "                            reference_seq)\n",
    "        results.append([taskname, *rhos])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278f222a",
   "metadata": {},
   "source": [
    "# RhlA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2607f40c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a947dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Task', 'Levenshtein Rho', 'BLOSUM62 Rho'],\n",
       " ['1_vs_rest_sum5a', -0.4677245318296993, -0.3373569334669312]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def levenshtein_to_fitness_rhla():\n",
    "\n",
    "    # Define the different rhla inputs\n",
    "    rhla_refseq_file = \"/home/Lxc/FLIP/tasks//RhlA//Rhla.fasta\"\n",
    "    rhla_taskfolder = \"//home/Lxc/FLIP/tasks/RhlA/tasks\"\n",
    "    rhla_task_to_file = {\n",
    "        #\"design\": \"design_task_regression.csv\",\n",
    "        #\"design_reversed\": \"design_task_reversed_regression.csv\",\n",
    "        #\"natural1\": \"natural_task_1_regression.csv\",\n",
    "        #\"natural2\": \"natural_task_2_regression.csv \"\n",
    "        '1_vs_rest_sum5a' : '1_vs_rest_sum5a.csv'\n",
    "    }\n",
    "\n",
    "    return evaluate_tasks(rhla_refseq_file,\n",
    "                          rhla_taskfolder,\n",
    "                          rhla_task_to_file)\n",
    "\n",
    "levenshtein_to_fitness_rhla()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d344c-51e1-4410-8bf2-2dfedfae27d4",
   "metadata": {},
   "source": [
    "# AAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a27cb5e-37fc-4b4c-9f85-405fbd65ce8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqs not aligned\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Task', 'Levenshtein Rho', 'BLOSUM62 Rho'],\n",
       " ['test', -0.11424957109787072, None]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def levenshtein_to_fitness_aav():\n",
    "\n",
    "    # Define the different aav inputs\n",
    "    aav_refseq_file = \"/home/Lxc/FLIP/tasks/avv/P03135.fasta\"\n",
    "    aav_taskfolder = \"/home/Lxc/FLIP/tasks/avv/tasks\"\n",
    "    aav_task_to_file = {\n",
    "        #\"design\": \"design_task_regression.csv\",\n",
    "        #\"design_reversed\": \"design_task_reversed_regression.csv\",\n",
    "        #\"natural1\": \"natural_task_1_regression.csv\",\n",
    "        #\"natural2\": \"natural_task_2_regression.csv\"\n",
    "        'test' : 'sampled.csv'\n",
    "    }\n",
    "\n",
    "    return evaluate_tasks(aav_refseq_file,\n",
    "                          aav_taskfolder,\n",
    "                          aav_task_to_file)\n",
    "\n",
    "levenshtein_to_fitness_aav()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113d1b11-9d41-4efc-8594-047adfe6c467",
   "metadata": {},
   "source": [
    "# Cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f370b28b-b1d9-4d18-8246-5075c7d4ec12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Task', 'Levenshtein Rho', 'BLOSUM62 Rho'],\n",
       " ['neg', -0.010226623065258516, None],\n",
       " ['pos', 0.13659949947831676, None]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def levenshtein_to_fitness_cas():\n",
    "\n",
    "    # Define the different cas inputs\n",
    "    refseq_file = \"../tasks/cas/cas9_sequence.fasta\"\n",
    "    taskfolder = \"../tasks/cas/tasks/\"\n",
    "    task_to_file = {\n",
    "        \"neg\": \"pi_domain_log_negative_selection_regression.csv\",\n",
    "        \"pos\": \"pi_domain_log_positive_selection_regression.csv\"\n",
    "    }\n",
    "\n",
    "    return evaluate_tasks(refseq_file,\n",
    "                          taskfolder,\n",
    "                          task_to_file)\n",
    "\n",
    "levenshtein_to_fitness_cas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace7f2e3-9129-4ac7-ad0d-f0ba29c448f2",
   "metadata": {},
   "source": [
    "# GB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63a23f70-da19-4172-91ab-45767de6654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n",
      "0.82\n",
      "0.57\n",
      "0.58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Task', 'Levenshtein Rho', 'BLOSUM62 Rho'],\n",
       " ['task_1', 0.3047852087567866, 0.2701889946573201],\n",
       " ['task_2', 0.28229457346871134, 0.24700573501708337],\n",
       " ['task_3', 0.21744875789758747, 0.17983746402576165],\n",
       " ['task_4', 0.1312655379831337, 0.08840527913469598]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def levenshtein_to_fitness_gb1():\n",
    "    \n",
    "    # Define the inputs\n",
    "    refseq_file = \"/home/Lxc/FLIP/tasks/SpCas9/SpCas9.fasta\"\n",
    "    taskfolder = \"/home/Lxc/FLIP/tasks/SpCas9/tasks\"\n",
    "    task_to_file = {\n",
    "        \"task_1\": \"SpCas9_mean-0vsrest-df1.csv\",\n",
    "        \"task_2\": \"SpCas9_mean-1vsrest-df1.csv\",\n",
    "        \"task_3\": \"SpCas9_mean-2vsrest-df1.csv\",\n",
    "        \"task_4\": \"SpCas9_mean-3vsrest-df1.csv\",\n",
    "        #'test1' : '0_vs_rest_sum.csv',\n",
    "        #'test2' : '1_vs_rest_sum.csv',\n",
    "        #'test3' : '2_vs_rest_sum.csv',\n",
    "        #'test4' : '3_vs_rest_sum.csv',\n",
    "        #'test5' : '0_vs_rest_sum5a.csv',\n",
    "        #'test6' : '1_vs_rest_sum5a.csv',\n",
    "        #'test7' : '2_vs_rest_sum5a.csv',\n",
    "        #'test8' : '3_vs_rest_sum5a.csv'\n",
    "    \n",
    "\n",
    "    }\n",
    "    \n",
    "    return evaluate_tasks(refseq_file,\n",
    "                          taskfolder,\n",
    "                          task_to_file)\n",
    "\n",
    "levenshtein_to_fitness_gb1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d10557a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Task', 'Levenshtein Rho', 'BLOSUM62 Rho'],\n",
       " ['test1', 0.30827452339378897, 0.2737801574576318]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def levenshtein_to_fitness_gb1():\n",
    "    \n",
    "    # Define the inputs\n",
    "    refseq_file = \"/home/Lxc/FLIP/tasks/RhlA/Rhla.fasta\"\n",
    "    taskfolder = \"/home/Lxc/FLIP/tasks/RhlA/tasks\"\n",
    "    task_to_file = {\n",
    "        #\"task_1\": \"four_mutations_task_1.csv\",\n",
    "        #\"task_2\": \"four_mutations_task_2.csv\",\n",
    "        #\"task_3\": \"four_mutations_task_3.csv\",\n",
    "        #\"task_4\": \"four_mutations_task_4.csv\"\n",
    "        'test1' : 'SpCas9_mean-0vsrest-df1.csv'\n",
    "      \n",
    "    \n",
    "\n",
    "    }\n",
    "    \n",
    "    return evaluate_tasks(refseq_file,\n",
    "                          taskfolder,\n",
    "                          task_to_file)\n",
    "\n",
    "levenshtein_to_fitness_gb1()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio-benchmarks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
