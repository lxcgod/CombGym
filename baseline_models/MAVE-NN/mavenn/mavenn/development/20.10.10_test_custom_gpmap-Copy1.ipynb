{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/jkinney/github/mavenn/mavenn']\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Insert path to mavenn beginning of path\n",
    "import os\n",
    "import sys\n",
    "abs_path_to_mavenn = os.path.abspath('../../')\n",
    "sys.path.insert(0, abs_path_to_mavenn)\n",
    "\n",
    "# Load mavenn\n",
    "import mavenn\n",
    "print(mavenn.__path__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_set</th>\n",
       "      <th>y</th>\n",
       "      <th>dy</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>-3.751854</td>\n",
       "      <td>0.444200</td>\n",
       "      <td>AAAGCAAAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>-2.697741</td>\n",
       "      <td>0.369972</td>\n",
       "      <td>AAAGCAAAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>-2.242947</td>\n",
       "      <td>0.575121</td>\n",
       "      <td>AAAGCAAAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>-3.067251</td>\n",
       "      <td>0.357014</td>\n",
       "      <td>AAAGCAAAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>-2.987074</td>\n",
       "      <td>0.472637</td>\n",
       "      <td>AAAGCAACA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   training_set         y        dy          x\n",
       "0         False -3.751854  0.444200  AAAGCAAAA\n",
       "1          True -2.697741  0.369972  AAAGCAAAC\n",
       "2          True -2.242947  0.575121  AAAGCAAAG\n",
       "3         False -3.067251  0.357014  AAAGCAAAT\n",
       "4         False -2.987074  0.472637  AAAGCAACA"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load example data\n",
    "data_df = mavenn.load_example_dataset('mpsa')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training N: 17,498\n",
      "testing N: 4,431\n"
     ]
    }
   ],
   "source": [
    "# Split into trianing and test data\n",
    "ix = data_df['training_set']\n",
    "L = len(data_df['x'][0])\n",
    "train_df = data_df[ix]\n",
    "print(f'training N: {len(train_df):,}')\n",
    "test_df = data_df[~ix]\n",
    "print(f'testing N: {len(test_df):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "    'regression_type':'GE',\n",
    "    'L':L,\n",
    "    'alphabet':'dna',\n",
    "    'ge_nonlinearity_type':'nonlinear',\n",
    "    'gpmap_type':'mlp',\n",
    "    'ge_noise_model_type':'SkewedT',\n",
    "    'ge_heteroskedasticity_order':2\n",
    "}\n",
    "\n",
    "fit_kwargs={'learning_rate':.005,\n",
    "            'epochs':100,\n",
    "            'batch_size': 200,\n",
    "            'early_stopping': True,\n",
    "            'early_stopping_patience': 100,\n",
    "            'linear_initialization': False}\n",
    "\n",
    "file_name = 'mpsa_ge_blackbox'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 17,498 observations set as training data.\n",
      "Data shuffled.\n",
      "Time to set data: 0.366 sec.\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 250.9751 - I_var: -0.5099 - val_loss: 218.2813 - val_I_var: -0.3024\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 195.1004 - I_var: -0.1216 - val_loss: 179.0225 - val_I_var: -0.0175\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 168.9310 - I_var: 0.0680 - val_loss: 166.3812 - val_I_var: 0.0752\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 159.2676 - I_var: 0.1386 - val_loss: 170.1410 - val_I_var: 0.0484\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 154.9829 - I_var: 0.1703 - val_loss: 161.5241 - val_I_var: 0.1107\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 154.7418 - I_var: 0.1730 - val_loss: 161.1336 - val_I_var: 0.1131\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 155.5118 - I_var: 0.1670 - val_loss: 157.7259 - val_I_var: 0.1392\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 151.0095 - I_var: 0.2001 - val_loss: 160.2047 - val_I_var: 0.1208\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 149.8466 - I_var: 0.2098 - val_loss: 160.8454 - val_I_var: 0.1190\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 149.8477 - I_var: 0.2110 - val_loss: 153.2397 - val_I_var: 0.1754\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 150.1618 - I_var: 0.2094 - val_loss: 154.0228 - val_I_var: 0.1697\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 141.9769 - I_var: 0.2698 - val_loss: 150.2278 - val_I_var: 0.1986\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 145.9018 - I_var: 0.2412 - val_loss: 158.8167 - val_I_var: 0.1355\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 146.7645 - I_var: 0.2358 - val_loss: 162.8024 - val_I_var: 0.1090\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 141.1851 - I_var: 0.2762 - val_loss: 144.4989 - val_I_var: 0.2420\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 139.8310 - I_var: 0.2869 - val_loss: 145.8764 - val_I_var: 0.2319\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 146.4805 - I_var: 0.2386 - val_loss: 144.7375 - val_I_var: 0.2420\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 137.7690 - I_var: 0.3029 - val_loss: 144.0071 - val_I_var: 0.2462\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 137.3004 - I_var: 0.3065 - val_loss: 141.8163 - val_I_var: 0.2651\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 139.3284 - I_var: 0.2924 - val_loss: 143.5037 - val_I_var: 0.2502\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 136.8215 - I_var: 0.3112 - val_loss: 147.0609 - val_I_var: 0.2267\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 137.4258 - I_var: 0.3064 - val_loss: 144.5613 - val_I_var: 0.2429\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 143.5481 - I_var: 0.2622 - val_loss: 149.2614 - val_I_var: 0.2095\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 134.7343 - I_var: 0.3264 - val_loss: 140.4910 - val_I_var: 0.2746\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 132.2228 - I_var: 0.3450 - val_loss: 147.8077 - val_I_var: 0.2218\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 139.3001 - I_var: 0.2941 - val_loss: 145.2649 - val_I_var: 0.2399\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 133.1039 - I_var: 0.3390 - val_loss: 135.9553 - val_I_var: 0.3067\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 135.0312 - I_var: 0.3251 - val_loss: 143.0024 - val_I_var: 0.2548\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 135.7834 - I_var: 0.3193 - val_loss: 139.0710 - val_I_var: 0.2861\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 138.4509 - I_var: 0.3006 - val_loss: 142.7946 - val_I_var: 0.2577\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 135.7540 - I_var: 0.3200 - val_loss: 141.3313 - val_I_var: 0.2663\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 135.6699 - I_var: 0.3203 - val_loss: 136.6638 - val_I_var: 0.3019\n",
      "Epoch 33/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 133.4585 - I_var: 0.3363 - val_loss: 144.0445 - val_I_var: 0.2517\n",
      "Epoch 34/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 132.6095 - I_var: 0.3426 - val_loss: 143.1754 - val_I_var: 0.2544\n",
      "Epoch 35/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 133.4136 - I_var: 0.3368 - val_loss: 132.2716 - val_I_var: 0.3331\n",
      "Epoch 36/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 132.3950 - I_var: 0.3440 - val_loss: 134.3227 - val_I_var: 0.3190\n",
      "Epoch 37/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 131.0706 - I_var: 0.3539 - val_loss: 137.7545 - val_I_var: 0.2940\n",
      "Epoch 38/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 131.8027 - I_var: 0.3486 - val_loss: 141.5544 - val_I_var: 0.2658\n",
      "Epoch 39/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 132.8004 - I_var: 0.3411 - val_loss: 142.3306 - val_I_var: 0.2609\n",
      "Epoch 40/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 131.8867 - I_var: 0.3477 - val_loss: 141.1235 - val_I_var: 0.2710\n",
      "Epoch 41/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 131.8360 - I_var: 0.3480 - val_loss: 141.0002 - val_I_var: 0.2708\n",
      "Epoch 42/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 135.3541 - I_var: 0.3226 - val_loss: 135.8614 - val_I_var: 0.3089\n",
      "Epoch 43/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 135.3020 - I_var: 0.3232 - val_loss: 135.6622 - val_I_var: 0.3101\n",
      "Epoch 44/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 132.3147 - I_var: 0.3447 - val_loss: 138.6826 - val_I_var: 0.2863\n",
      "Epoch 45/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 133.2794 - I_var: 0.3379 - val_loss: 139.2780 - val_I_var: 0.2836\n",
      "Epoch 46/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 138.4467 - I_var: 0.3004 - val_loss: 137.6553 - val_I_var: 0.2957\n",
      "Epoch 47/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 132.1001 - I_var: 0.3465 - val_loss: 140.7848 - val_I_var: 0.2727\n",
      "Epoch 48/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 134.1023 - I_var: 0.3321 - val_loss: 140.2333 - val_I_var: 0.2777\n",
      "Epoch 49/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 135.2672 - I_var: 0.3236 - val_loss: 137.1081 - val_I_var: 0.2994\n",
      "Epoch 50/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 133.9003 - I_var: 0.3335 - val_loss: 138.4428 - val_I_var: 0.2903\n",
      "Epoch 51/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 132.5905 - I_var: 0.3430 - val_loss: 138.1279 - val_I_var: 0.2941\n",
      "Epoch 52/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 135.6569 - I_var: 0.3208 - val_loss: 138.7196 - val_I_var: 0.2894\n",
      "Epoch 53/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 130.7734 - I_var: 0.3564 - val_loss: 136.3118 - val_I_var: 0.3050\n",
      "Epoch 54/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 131.1682 - I_var: 0.3534 - val_loss: 136.6902 - val_I_var: 0.3028\n",
      "Epoch 55/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 131.6943 - I_var: 0.3497 - val_loss: 143.5193 - val_I_var: 0.2527\n",
      "Epoch 56/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 130.7437 - I_var: 0.3567 - val_loss: 135.3722 - val_I_var: 0.3141\n",
      "Epoch 57/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 129.3091 - I_var: 0.3671 - val_loss: 139.2861 - val_I_var: 0.2859\n",
      "Epoch 58/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 132.7209 - I_var: 0.3424 - val_loss: 147.3499 - val_I_var: 0.2230\n",
      "Epoch 59/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 131.1083 - I_var: 0.3539 - val_loss: 138.5224 - val_I_var: 0.2897\n",
      "Epoch 60/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 127.6993 - I_var: 0.3787 - val_loss: 136.2584 - val_I_var: 0.3068\n",
      "Epoch 61/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 128.7646 - I_var: 0.3711 - val_loss: 137.5434 - val_I_var: 0.2976\n",
      "Epoch 62/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 128.1882 - I_var: 0.3752 - val_loss: 141.4171 - val_I_var: 0.2689\n",
      "Epoch 63/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 129.8521 - I_var: 0.3632 - val_loss: 135.0972 - val_I_var: 0.3151\n",
      "Epoch 64/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 128.2135 - I_var: 0.3751 - val_loss: 134.8678 - val_I_var: 0.3164\n",
      "Epoch 65/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 129.1806 - I_var: 0.3680 - val_loss: 136.9638 - val_I_var: 0.3012\n",
      "Epoch 66/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 129.1811 - I_var: 0.3680 - val_loss: 139.7086 - val_I_var: 0.2832\n",
      "Epoch 67/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 132.5093 - I_var: 0.3437 - val_loss: 138.5463 - val_I_var: 0.2882\n",
      "Epoch 68/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 127.3913 - I_var: 0.3806 - val_loss: 135.2789 - val_I_var: 0.3131\n",
      "Epoch 69/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 130.1799 - I_var: 0.3605 - val_loss: 141.7529 - val_I_var: 0.2668\n",
      "Epoch 70/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 129.1172 - I_var: 0.3682 - val_loss: 135.5860 - val_I_var: 0.3108\n",
      "Epoch 71/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 129.0188 - I_var: 0.3688 - val_loss: 135.3486 - val_I_var: 0.3122\n",
      "Epoch 72/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 127.5986 - I_var: 0.3789 - val_loss: 135.7368 - val_I_var: 0.3106\n",
      "Epoch 73/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 127.6180 - I_var: 0.3789 - val_loss: 136.9256 - val_I_var: 0.3002\n",
      "Epoch 74/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 127.2721 - I_var: 0.3814 - val_loss: 136.1442 - val_I_var: 0.3061\n",
      "Epoch 75/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 128.1758 - I_var: 0.3748 - val_loss: 139.5056 - val_I_var: 0.2819\n",
      "Epoch 76/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 128.2252 - I_var: 0.3743 - val_loss: 142.2677 - val_I_var: 0.2648\n",
      "Epoch 77/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 128.3198 - I_var: 0.3737 - val_loss: 134.4204 - val_I_var: 0.3191\n",
      "Epoch 78/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 131.4688 - I_var: 0.3509 - val_loss: 137.0963 - val_I_var: 0.3000\n",
      "Epoch 79/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 128.1482 - I_var: 0.3748 - val_loss: 136.9456 - val_I_var: 0.3016\n",
      "Epoch 80/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 127.6026 - I_var: 0.3785 - val_loss: 139.9607 - val_I_var: 0.2811\n",
      "Epoch 81/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 127.6958 - I_var: 0.3779 - val_loss: 140.6680 - val_I_var: 0.2726\n",
      "Epoch 82/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 129.2302 - I_var: 0.3670 - val_loss: 139.6587 - val_I_var: 0.2828\n",
      "Epoch 83/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 129.7737 - I_var: 0.3630 - val_loss: 134.2391 - val_I_var: 0.3200\n",
      "Epoch 84/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 130.4985 - I_var: 0.3577 - val_loss: 138.7336 - val_I_var: 0.2891\n",
      "Epoch 85/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 133.4311 - I_var: 0.3366 - val_loss: 148.2949 - val_I_var: 0.2180\n",
      "Epoch 86/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 135.7865 - I_var: 0.3195 - val_loss: 141.8510 - val_I_var: 0.2640\n",
      "Epoch 87/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 130.7155 - I_var: 0.3560 - val_loss: 146.4949 - val_I_var: 0.2295\n",
      "Epoch 88/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 131.6275 - I_var: 0.3495 - val_loss: 136.4019 - val_I_var: 0.3031\n",
      "Epoch 89/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 128.4524 - I_var: 0.3725 - val_loss: 135.5928 - val_I_var: 0.3100\n",
      "Epoch 90/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 128.1182 - I_var: 0.3750 - val_loss: 137.3798 - val_I_var: 0.2976\n",
      "Epoch 91/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 128.4747 - I_var: 0.3724 - val_loss: 138.4490 - val_I_var: 0.2906\n",
      "Epoch 92/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 127.3075 - I_var: 0.3807 - val_loss: 139.1152 - val_I_var: 0.2857\n",
      "Epoch 93/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 128.8935 - I_var: 0.3693 - val_loss: 140.0912 - val_I_var: 0.2788\n",
      "Epoch 94/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 129.1714 - I_var: 0.3671 - val_loss: 137.9930 - val_I_var: 0.2926\n",
      "Epoch 95/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 130.1095 - I_var: 0.3604 - val_loss: 146.6604 - val_I_var: 0.2297\n",
      "Epoch 96/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 128.5316 - I_var: 0.3717 - val_loss: 136.0863 - val_I_var: 0.3064\n",
      "Epoch 97/100\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 125.9276 - I_var: 0.3906 - val_loss: 139.7843 - val_I_var: 0.2773\n",
      "Epoch 98/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 131.3506 - I_var: 0.3513 - val_loss: 139.3341 - val_I_var: 0.2832\n",
      "Epoch 99/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 127.1947 - I_var: 0.3817 - val_loss: 134.7058 - val_I_var: 0.3170\n",
      "Epoch 100/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 126.2478 - I_var: 0.3886 - val_loss: 134.4890 - val_I_var: 0.3177\n",
      "Training time: 23.4 seconds\n",
      "Model saved to these files:\n",
      "\tmpsa_ge_blackbox.pickle\n",
      "\tmpsa_ge_blackbox.h5\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "\n",
    "    # Set seeed\n",
    "    mavenn.set_seed(0)\n",
    "\n",
    "    # Define model\n",
    "    model = mavenn.Model(**model_kwargs)\n",
    "\n",
    "    # Set training data\n",
    "    model.set_data(x=train_df['x'],\n",
    "                   y=train_df['y'])\n",
    "\n",
    "    # Fit model to data\n",
    "    model.fit(**fit_kwargs)\n",
    "    \n",
    "    # Save model\n",
    "    model.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 36)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer_gpmap.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['L', 'C', 'alphabet', 'theta_0', 'theta_lc', 'theta_lclc', 'theta_mlp', 'logomaker_df'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_theta().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[ 1.58156380e-01, -9.93106589e-02, -8.18898901e-03,\n",
       "           1.91798314e-01,  8.13778713e-02,  2.73752189e-03,\n",
       "           9.29782242e-02,  1.95636362e-01,  1.92756012e-01,\n",
       "          -2.63394924e-14],\n",
       "         [ 8.24619159e-02, -4.97937910e-02,  5.57352193e-02,\n",
       "          -1.61574967e-02,  1.82693928e-01, -9.38864127e-02,\n",
       "          -7.76444376e-02,  1.11436360e-01,  5.56413457e-02,\n",
       "          -1.05564558e-35],\n",
       "         [-3.57295901e-01, -1.31085768e-01, -4.23249006e-02,\n",
       "           1.28747839e-02,  4.84974273e-02,  2.35908836e-01,\n",
       "           1.07815169e-01, -3.38197909e-02, -3.58532995e-01,\n",
       "           3.24944029e-37],\n",
       "         [-2.79000495e-02, -8.41639191e-02, -3.37245725e-02,\n",
       "           1.60978828e-02, -8.68158400e-01, -8.56827758e-03,\n",
       "           1.18786044e-01,  1.19688578e-01,  2.88222462e-01,\n",
       "          -8.92286093e-36],\n",
       "         [ 1.39934361e-01, -8.98744911e-03, -7.43143782e-02,\n",
       "           5.84351793e-02,  5.93201339e-01, -1.52412683e-01,\n",
       "          -2.39134610e-01,  1.02613054e-01,  3.64926010e-01,\n",
       "          -2.66427120e-16],\n",
       "         [ 3.78968567e-03, -4.25054766e-02,  7.52497613e-02,\n",
       "           7.16562867e-02, -1.98336184e-01, -3.82908136e-02,\n",
       "          -3.71349379e-02,  2.39183418e-02,  1.87609360e-01,\n",
       "          -7.96645092e-36],\n",
       "         [-5.21821715e-02, -8.28090161e-02,  8.43235031e-02,\n",
       "           5.62580675e-02, -4.11237299e-01,  2.27002457e-01,\n",
       "           2.35687554e-01, -3.10879853e-02, -5.36919475e-01,\n",
       "          -1.04335878e-35],\n",
       "         [-2.14917481e-01, -5.07920608e-02,  4.29431237e-02,\n",
       "           7.03020915e-02, -3.96575153e-01, -1.30507603e-01,\n",
       "           4.38741557e-02,  1.21225953e-01,  3.15058678e-01,\n",
       "           1.92365724e-37],\n",
       "         [-3.36924195e-01, -9.27611291e-02, -7.55341202e-02,\n",
       "           9.22984481e-02, -4.08590883e-01, -2.01841339e-01,\n",
       "           2.96348423e-01,  5.99001706e-01, -6.34674579e-02,\n",
       "          -1.25799057e-25],\n",
       "         [-5.16789556e-01, -1.45852361e-02,  4.20157649e-02,\n",
       "           1.24941073e-01, -3.93125951e-01,  9.63198580e-03,\n",
       "          -1.05624996e-01,  3.43973279e-01, -2.30584428e-01,\n",
       "          -7.91413195e-36],\n",
       "         [ 5.99932492e-01,  1.50725156e-01, -6.53501898e-02,\n",
       "           3.55286092e-01,  6.00464106e-01, -7.48624727e-02,\n",
       "          -1.11214062e-02,  3.59065324e-01, -8.48627627e-01,\n",
       "           2.13290672e-34],\n",
       "         [-2.26239830e-01, -1.99080274e-01, -2.55257953e-02,\n",
       "          -3.03289801e-01, -6.36441112e-01,  3.02999079e-01,\n",
       "          -2.10596383e-01, -6.54264331e-01,  8.91690493e-01,\n",
       "           9.63807344e-37],\n",
       "         [-2.82923155e-36, -3.84000944e-36, -3.93510438e-37,\n",
       "          -4.62922647e-38, -4.62082424e-36, -2.30536081e-36,\n",
       "           6.38008384e-36, -5.07462002e-36,  1.12452874e-35,\n",
       "          -1.19840580e-35],\n",
       "         [-7.19876643e-36,  4.00346012e-36,  3.45152663e-36,\n",
       "           1.11558790e-35, -7.77555003e-36, -1.23546365e-36,\n",
       "          -1.38649932e-36, -1.23585825e-36, -1.19193893e-35,\n",
       "          -1.18619319e-36],\n",
       "         [ 1.07005415e-02, -1.12539969e-01,  1.72727898e-01,\n",
       "           9.16059874e-03, -1.79869786e-01,  3.92730720e-02,\n",
       "           4.69697826e-02,  9.34798717e-02,  2.28880271e-02,\n",
       "          -1.96407876e-10],\n",
       "         [-3.54183106e-36, -7.15576400e-34,  6.20273299e-36,\n",
       "           8.20104900e-36, -1.13067059e-35,  5.35861340e-36,\n",
       "           9.28320117e-36, -2.70819183e-36,  8.69688032e-36,\n",
       "          -7.32645508e-36],\n",
       "         [ 3.31497909e-36,  6.54920823e-36,  8.00012190e-37,\n",
       "          -9.45835815e-34,  9.54322764e-36,  8.42464475e-36,\n",
       "           1.13211248e-35,  5.48083712e-36, -1.15046509e-35,\n",
       "          -3.71943553e-36],\n",
       "         [-1.15457249e+00, -3.84140521e-01,  3.55872996e-02,\n",
       "           7.41453841e-02, -5.10429800e-01,  3.85663033e-01,\n",
       "          -6.01660758e-02,  2.18663424e-01,  2.74665710e-02,\n",
       "          -2.69874246e-36],\n",
       "         [-1.05133484e-35,  7.36501092e-36, -5.98261120e-36,\n",
       "          -1.02255037e-35,  6.13682380e-36,  6.10351622e-36,\n",
       "          -5.88497141e-36, -1.21119669e-35,  4.49743392e-36,\n",
       "          -9.82365522e-36],\n",
       "         [ 5.30391216e-01,  1.48661703e-01, -7.86938816e-02,\n",
       "           1.45660043e-01,  1.63623154e-01, -2.45860666e-01,\n",
       "           3.08205813e-01,  1.45565748e-01,  3.82557698e-02,\n",
       "          -9.37153410e-11],\n",
       "         [ 5.32066822e-01,  2.80930430e-01, -9.46197510e-02,\n",
       "          -1.89453773e-02,  1.85849443e-01,  1.41357660e-01,\n",
       "          -7.64114797e-01, -1.16189686e-03,  1.68167308e-01,\n",
       "          -8.56369324e-22],\n",
       "         [-5.15202045e-01, -5.47840536e-01, -6.69312105e-02,\n",
       "           1.53447956e-01, -7.13369846e-02, -3.46556753e-01,\n",
       "           3.25239033e-01,  3.92443448e-01,  6.20156564e-02,\n",
       "          -1.17437537e-36],\n",
       "         [ 7.57875592e-02,  4.72027063e-01,  1.17167845e-01,\n",
       "          -1.54169336e-01, -1.06739834e-01,  3.69755566e-01,\n",
       "           5.38155258e-01,  8.76385570e-02, -1.50973350e-01,\n",
       "          -2.39988552e-22],\n",
       "         [-3.92015874e-01, -7.89626300e-01, -7.22656250e-02,\n",
       "           2.61396796e-01, -2.94510096e-01, -2.31360883e-01,\n",
       "           4.83761281e-02, -1.32241353e-01,  7.45574534e-02,\n",
       "           7.30300259e-36],\n",
       "         [ 1.33665457e-01,  6.52308524e-01,  1.70742005e-01,\n",
       "          -1.61418453e-01,  1.32231060e-02, -4.97165531e-01,\n",
       "           6.93600625e-02, -9.87051874e-02,  9.24119055e-02,\n",
       "           6.16267277e-22],\n",
       "         [ 4.07743752e-02, -2.36142904e-01, -4.24074046e-02,\n",
       "           1.62662938e-01, -1.55620530e-01, -1.91457897e-01,\n",
       "           2.11875111e-01,  1.91139564e-01, -5.27464822e-02,\n",
       "          -8.97318905e-21],\n",
       "         [-1.19418852e-01, -1.59355596e-01, -8.21395889e-02,\n",
       "           4.85080406e-02, -1.60786793e-01,  6.21072590e-01,\n",
       "          -4.11944568e-01,  4.80674207e-01, -9.14779957e-03,\n",
       "           5.09830891e-36],\n",
       "         [-1.61446948e-02, -8.06354165e-01,  4.50158259e-05,\n",
       "           1.79908618e-01, -2.76560821e-02,  1.76815346e-01,\n",
       "           3.36781800e-01, -2.26331607e-01,  3.46192047e-02,\n",
       "           6.50714354e-37],\n",
       "         [-2.86559034e-02, -3.32145840e-01,  3.89265537e-01,\n",
       "           1.25365570e-01, -1.49906829e-01,  2.86656529e-01,\n",
       "          -2.25799568e-02,  1.27994150e-01,  4.85957600e-02,\n",
       "          -8.04240748e-37],\n",
       "         [-3.93778414e-01, -2.05751359e-01,  3.80648971e-02,\n",
       "          -2.43262261e-01, -1.96585894e-01, -6.04239712e-03,\n",
       "           1.07941985e-01,  2.53518224e-01,  5.88530228e-02,\n",
       "          -1.07807138e-35],\n",
       "         [ 2.71969408e-01,  4.34359670e-01, -1.13718069e+00,\n",
       "           3.14768821e-01, -3.59938778e-02,  9.19179469e-02,\n",
       "          -1.69356707e-02,  7.31785297e-02,  9.88606364e-02,\n",
       "          -1.54301265e-14],\n",
       "         [-1.73832551e-01, -2.27870226e-01,  3.41191232e-01,\n",
       "          -1.34101436e-01, -7.72712827e-02, -4.38262433e-01,\n",
       "           1.14080496e-01, -2.53517270e-01, -9.75508392e-02,\n",
       "          -8.09037790e-36],\n",
       "         [-2.96288699e-01, -1.64158717e-01, -5.57039082e-02,\n",
       "           3.73973072e-01,  3.33782658e-03,  6.71848580e-02,\n",
       "           6.95818290e-02,  3.40428087e-03,  6.57655299e-03,\n",
       "          -6.82664255e-36],\n",
       "         [-3.05393010e-01,  1.19112367e-02, -1.38793692e-01,\n",
       "          -9.33170840e-02, -9.53191221e-02, -3.00612766e-02,\n",
       "          -3.89027037e-02,  8.82447287e-02, -7.10941805e-03,\n",
       "          -7.20511156e-24],\n",
       "         [-2.52038330e-01, -3.23257208e-01, -7.58788526e-01,\n",
       "          -1.02933384e-01, -2.20847670e-02, -3.15543711e-02,\n",
       "           2.51185372e-02,  1.69628650e-01,  8.65235850e-02,\n",
       "          -2.70069522e-36],\n",
       "         [ 4.74917114e-01,  1.19655602e-01,  6.03601336e-01,\n",
       "           3.74511853e-02, -1.09810010e-01, -2.14522728e-03,\n",
       "           1.07418606e-02,  7.90974274e-02, -2.58830618e-02,\n",
       "          -1.04041000e-35]], dtype=float32),\n",
       "  array([-5.4154310e-02, -1.7243935e-01,  2.6531858e-02,  1.5754566e-01,\n",
       "         -1.6426656e-01,  5.1181965e-02,  1.1112334e-01,  2.0321633e-01,\n",
       "          6.5361165e-02, -1.9640829e-10], dtype=float32)],\n",
       " [array([[-2.13725463e-01, -1.32490441e-01,  2.86411017e-01,\n",
       "           7.62869835e-01, -1.47288099e-01,  1.48720639e-02,\n",
       "           6.65880098e-36, -3.73427548e-32],\n",
       "         [ 8.95598754e-02,  6.47313058e-01,  2.19910294e-01,\n",
       "           6.73176825e-01, -2.96983302e-01,  9.62206572e-02,\n",
       "           2.77385457e-36,  5.60036777e-32],\n",
       "         [ 2.11396944e-02, -1.02543645e-01, -1.57239661e-02,\n",
       "          -6.67730093e-01,  2.63288528e-01,  8.17720741e-02,\n",
       "           3.93132979e-36, -2.56235699e-32],\n",
       "         [ 3.89104672e-02,  2.54936188e-01,  1.49503246e-01,\n",
       "           1.26929119e-01,  2.81739175e-01, -2.12025180e-01,\n",
       "          -4.21254259e-18, -2.76939770e-27],\n",
       "         [-2.03104734e-01,  4.47958410e-02,  8.39741901e-02,\n",
       "           6.67160988e-01, -1.82585627e-01,  2.60522286e-03,\n",
       "          -1.89218394e-36, -8.45456312e-33],\n",
       "         [ 2.79639125e-01,  5.60281985e-03, -1.37006015e-01,\n",
       "          -3.10698748e-01,  7.40878209e-02,  4.83311892e-01,\n",
       "          -8.32843888e-17, -4.65613423e-33],\n",
       "         [-2.03099146e-01, -1.54192924e-01, -2.48905510e-01,\n",
       "          -3.01096499e-01,  2.62398124e-01,  2.71839589e-01,\n",
       "          -1.01235634e-35, -4.30487396e-32],\n",
       "         [ 1.99551776e-01, -1.07232794e-01, -1.38653457e-01,\n",
       "          -4.94119525e-02, -2.58420724e-02, -9.73848224e-01,\n",
       "          -2.49843381e-22, -4.61756016e-32],\n",
       "         [-4.07844901e-01, -9.68639925e-02, -3.59884314e-02,\n",
       "          -1.31486863e-01,  2.24033207e-01, -9.45062578e-01,\n",
       "           7.71569840e-36, -8.16116105e-32],\n",
       "         [ 1.01295783e-09,  8.90701662e-12, -3.67082395e-14,\n",
       "           2.74891931e-06,  3.47478126e-05,  6.85740457e-36,\n",
       "          -1.19645042e-36, -7.17986124e-36]], dtype=float32),\n",
       "  array([ 2.0622622e-02,  1.7333676e-01,  1.8448474e-01, -2.3929618e-01,\n",
       "          2.1872228e-01, -4.9855702e-02, -6.9483754e-17, -8.5990774e-32],\n",
       "        dtype=float32)],\n",
       " [array([[-2.6376718e-01, -4.5147047e-36,  2.8137204e-01,  1.9761094e-01,\n",
       "          -1.5695345e-19, -1.9855426e-04],\n",
       "         [ 1.8685307e-01, -6.5205513e-36,  1.5222783e-01,  2.5747091e-01,\n",
       "          -4.8407448e-05, -6.2418752e-04],\n",
       "         [ 2.0850080e-01, -8.3857879e-37, -5.6825720e-02,  1.7637323e-01,\n",
       "          -1.7660346e-07, -6.7432778e-04],\n",
       "         [ 7.6579058e-01,  9.3751051e-23, -2.1404174e-01, -7.2439820e-01,\n",
       "           4.1614257e-04, -2.9675951e-04],\n",
       "         [-4.7515836e-01, -2.0714580e-26,  3.7689459e-01,  4.5472589e-01,\n",
       "          -3.0218757e-06, -5.1720906e-03],\n",
       "         [-1.2971295e-01,  1.0096775e-35,  8.5835105e-01, -9.6233040e-01,\n",
       "           1.1764034e-35,  3.2921466e-28],\n",
       "         [-2.4004141e-36, -9.7883057e-36, -2.7785237e-37, -4.7547035e-36,\n",
       "          -3.6400003e-36, -9.0718088e-36],\n",
       "         [ 3.6611917e-36,  2.6052636e-36, -4.1329932e-32,  4.7441394e-32,\n",
       "           4.8075036e-36, -3.1184640e-36]], dtype=float32),\n",
       "  array([ 4.0729012e-02, -3.3442688e-10, -3.0163798e-01,  3.1732327e-01,\n",
       "         -4.6596434e-03, -2.3921828e-03], dtype=float32)],\n",
       " [array([[-7.3254621e-36, -1.6072237e-01,  5.6512821e-01, -5.0489247e-01],\n",
       "         [ 1.0907279e-35, -7.6457549e-36, -4.9950308e-28,  4.4826907e-09],\n",
       "         [-6.4746098e-36, -7.8714408e-02,  6.5764868e-01, -3.8271832e-01],\n",
       "         [-2.0777289e-13,  6.9088364e-01, -5.7019341e-01,  5.3550696e-01],\n",
       "         [-7.3866654e-36,  3.2711391e-36,  9.0657324e-03,  1.3966773e-02],\n",
       "         [-1.0211691e-36,  2.4122375e-03,  9.7894168e-04,  1.9110605e-02]],\n",
       "        dtype=float32),\n",
       "  array([-4.6274107e-13, -6.3904144e-02,  1.9181494e-01,  3.6261046e-01],\n",
       "        dtype=float32)],\n",
       " [array([[-4.5900253e-36,  4.0082765e-36],\n",
       "         [ 2.0459943e-01,  4.8750126e-01],\n",
       "         [-5.9983689e-01,  6.2878081e-03],\n",
       "         [ 6.0977715e-01, -2.0259291e-02]], dtype=float32),\n",
       "  array([ 0.46092102, -0.18823501], dtype=float32)],\n",
       " [array([[-0.6359422 ],\n",
       "         [ 0.24688773]], dtype=float32), array([0.20726393], dtype=float32)]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_theta()['theta_mlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = mavenn.load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get x and y\n",
    "x_test = test_df['x'].values\n",
    "y_test = test_df['y'].values\n",
    "dy_test = test_df['dy'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training history\n",
    "print('On test data:')\n",
    "\n",
    "# Compute likelihood information\n",
    "I_var, dI_var =  model.I_varlihood(x=x_test, y=y_test)\n",
    "print(f'I_var_test: {I_var:.3f} +- {dI_var:.3f} bits') \n",
    "\n",
    "# Compute predictive information\n",
    "I_pred, dI_pred = model.I_predictive(x=x_test, y=y_test)\n",
    "print(f'I_pred_test: {I_pred:.3f} +- {dI_pred:.3f} bits')\n",
    "\n",
    "# Compute intrinsic information\n",
    "I_intr, dI_intr = mavenn.I_intrinsic(y_values=y_test, dy_values=dy_test)\n",
    "print(f'I_intrinsic: {I_intr:.3f} +- {dI_intr:.3f} bits')\n",
    "\n",
    "# Compute percent info explained\n",
    "pct = 100*I_pred/I_intr\n",
    "dpct = 100*np.sqrt((dI_pred/I_intr)**2 + (dI_intr*I_pred/I_intr**2)**2)\n",
    "print(f'percent info explained: {pct:.1f}% +- {dpct:.1f}%')\n",
    "\n",
    "I_var_hist = model.history['I_var']\n",
    "val_I_var_hist = model.history['val_I_var']\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=[4,4])\n",
    "ax.plot(I_var_hist, label='I_var_train')\n",
    "ax.plot(val_I_var_hist, label='I_var_val')\n",
    "ax.axhline(I_var, color='C2', linestyle=':', label='I_var_test')\n",
    "ax.axhline(I_pred, color='C3', linestyle=':', label='I_pred_test')\n",
    "ax.axhline(I_intr, color='C4', linestyle=':', label='I_intrinsic')\n",
    "ax.legend()\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('bits')\n",
    "ax.set_title('training hisotry')\n",
    "ax.set_ylim([0, I_intr*1.2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict latent phentoype values (phi) on test data\n",
    "phi_test = model.x_to_phi(x_test)\n",
    "\n",
    "# Predict measurement values (yhat) on test data\n",
    "yhat_test = model.x_to_yhat(x_test)\n",
    "\n",
    "# Set phi lims and create grid in phi space\n",
    "phi_lim = [min(phi_test)-.5, max(phi_test)+.5]\n",
    "phi_grid = np.linspace(phi_lim[0], phi_lim[1], 1000)\n",
    "\n",
    "# Compute yhat each phi gridpoint\n",
    "yhat_grid = model.phi_to_yhat(phi_grid)\n",
    "\n",
    "# Compute 90% CI for each yhat\n",
    "q = [0.05, 0.95] #[0.16, 0.84]\n",
    "yqs_grid = model.yhat_to_yq(yhat_grid, q=q)\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(1, 1, figsize=[4, 4])\n",
    "\n",
    "# Illustrate measurement process with GE curve\n",
    "ax.scatter(phi_test, y_test, color='C0', s=5, alpha=.2, label='test data')\n",
    "ax.plot(phi_grid, yhat_grid, linewidth=2, color='C1',\n",
    "        label='$\\hat{y} = g(\\phi)$')\n",
    "ax.plot(phi_grid, yqs_grid[:, 0], linestyle='--', color='C1', label='68% CI')\n",
    "ax.plot(phi_grid, yqs_grid[:, 1], linestyle='--', color='C1')\n",
    "ax.set_xlim(phi_lim)\n",
    "ax.set_xlabel('latent phenotype ($\\phi$)')\n",
    "ax.set_ylabel('measurement ($y$)')\n",
    "ax.set_title('measurement process')\n",
    "ax.set_ylim([-6, 3])\n",
    "ax.legend()\n",
    "\n",
    "# Fix up plot\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pairwise parameters\n",
    "if model.gpmap_type in ['pairwise', 'neighbor']:\n",
    "    theta = model.get_theta()\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[8, 4])\n",
    "    mavenn.heatmap_pairwise(values=theta['theta_lclc'],\n",
    "                            alphabet=theta['alphabet'],\n",
    "                            ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
