{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/tareen/Desktop/Research_Projects/2020_mavenn_github/mavenn_local/mavenn']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/tareen/Desktop/Research_Projects/2020_mavenn_github/mavenn_local')\n",
    "import mavenn\n",
    "print(mavenn.__path__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df = mavenn.load_example_dataset('amyloid')\n",
    "# Show dataset size\n",
    "print(f'Number of amino acid variants: {len(data_df):,d}.')\n",
    "print(data_df.head())\n",
    "WT_seq = 'DAEFRHDSGYEVHHQKLVFFAEDVGSNKGAIIGLMVGGVVIA'\n",
    "\n",
    "# indices of training examples\n",
    "i_training = data_df['set']=='training'\n",
    "\n",
    "# get train examples.\n",
    "ABeta_train_df = data_df[i_training]\n",
    "# get test examples.\n",
    "ABeta_test_df = data_df[~i_training]\n",
    "\n",
    "x_train, y_train, dy_train  = ABeta_train_df['x'], ABeta_train_df['y'], ABeta_train_df['dy']\n",
    "x_test, y_test, dy_test  = ABeta_test_df['x'], ABeta_test_df['y'], ABeta_test_df['dy'] \n",
    "\n",
    "# Show dataset sizes\n",
    "print(f'Training set size: {len(x_train):6,d} observations')\n",
    "print(f'Test set size    : {len(x_test):6,d} observations')\n",
    "L = len(ABeta_train_df['x'][0])\n",
    "\n",
    "# Define model and set training data\n",
    "model = mavenn.Model(regression_type='GE',\n",
    "                     L=L,\n",
    "                     alphabet='protein*',\n",
    "                     gpmap_type='additive',\n",
    "                     ge_nonlinearity_hidden_nodes=20,\n",
    "                     ge_noise_model_type='Empirical',\n",
    "                     ge_nonlinearity_monotonic=True)\n",
    "\n",
    "model.set_data(x=x_train,\n",
    "               y=y_train,\n",
    "               dy=dy_train,\n",
    "               validation_flags=(data_df['set'] == 'validation'),\n",
    "               shuffle=True)\n",
    "\n",
    "# Fit model to data\n",
    "history = model.fit(learning_rate=1e-4,\n",
    "                    epochs=500,\n",
    "                    batch_size=64,\n",
    "                    early_stopping=True,\n",
    "                    early_stopping_patience=25,\n",
    "                    linear_initialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### 1. Compute Variational and Predictive Information ######\n",
    "\n",
    "print('On test data:')\n",
    "I_var, dI_var =  model.I_variational(x=x_test, y=y_test)\n",
    "print(f'I_var_test: {I_var:.3f} +- {dI_var:.3f} bits')\n",
    "\n",
    "# Compute predictive information\n",
    "I_pred, dI_pred = model.I_predictive(x=x_test, y=y_test)\n",
    "print(f'I_pred_test: {I_pred:.3f} +- {dI_pred:.3f} bits')\n",
    "\n",
    "# Get the history of I_var for train and validation sets\n",
    "I_var_hist = model.history['I_var']\n",
    "val_I_var_hist = model.history['val_I_var']\n",
    "\n",
    "fig, axs = plt.subplots(2,2,figsize=[10,10/1.6])\n",
    "\n",
    "# Plot the history of I_var for training and \n",
    "# validation sets as functions of epochs \n",
    "ax = axs[0,0]\n",
    "ax.plot(I_var_hist, label=r'I_var_train')\n",
    "ax.plot(val_I_var_hist, label=r'I_var_val')\n",
    "ax.axhline(I_var, color='C2', linestyle=':', \n",
    "           label=r'I_var_test')\n",
    "ax.axhline(I_pred, color='C3', linestyle=':', \n",
    "           label=r'I_pred_test')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('bits')\n",
    "ax.set_title('(a) training hisotry')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### 2. Loss functions as a function of epochs ######\n",
    "\n",
    "ax = axs[0,1]\n",
    "ax.plot(model.history['loss'], label='Training loss')\n",
    "ax.plot(model.history[r'val_loss'], label='Validation loss')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()\n",
    "ax.set_title('(b) history of loss function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### 3. Predict and plot latent phentoype values ######\n",
    "######           (phi) on test data                ######\n",
    "\n",
    "ax = axs[1,0]\n",
    "phi_test = model.x_to_phi(x_test)\n",
    "\n",
    "## Set phi lims and create grid in phi space\n",
    "phi_lim = [min(phi_test)-.5, max(phi_test)+.5]\n",
    "phi_grid = np.linspace(phi_lim[0], phi_lim[1], 1000)\n",
    "\n",
    "# Compute yhat each phi gridpoint\n",
    "yhat_grid = model.phi_to_yhat(phi_grid)\n",
    "\n",
    "# Compute 90% CI for each yhat\n",
    "q = [0.05, 0.95]\n",
    "yqs_grid = model.yhat_to_yq(yhat_grid, q=q)\n",
    "\n",
    "# Illustrate measurement process with GE curve\n",
    "ax.scatter(phi_test, y_test, color='C0', s=5, alpha=.2, \n",
    "           rasterized=True, label='test data')\n",
    "ax.plot(phi_grid, yhat_grid, linewidth=2, color='C1',\n",
    "        label='$\\hat{y} = g(\\phi)$')\n",
    "ax.fill_between(phi_grid, yqs_grid[:, 0], \n",
    "                yqs_grid[:, 1], alpha=0.3, color='C2',\n",
    "                edgecolor='red', lw=2, linestyle='--',\n",
    "                label='90% CI')\n",
    "ax.set_xlim(phi_lim)\n",
    "ax.set_xlabel('latent phenotype ($\\phi$)')\n",
    "ax.set_ylabel('Nucleation score($y$)')\n",
    "ax.set_title('(c) measurement process')\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### 4. Model Performance ######\n",
    "\n",
    "ax = axs[1,1]\n",
    "yhat_test = model.x_to_yhat(x_test)\n",
    "# Compute R^2 between yhat and y_test\n",
    "Rsq = np.corrcoef(yhat_test.ravel(), y_test)[0, 1]**2\n",
    "xlim = [-5.5,3]\n",
    "# Plot y_test vs. yhat_test\n",
    "ax.scatter(yhat_test, y_test, color='C0', s=5, alpha=.2, \n",
    "           rasterized=True, label='test data')\n",
    "ax.plot(xlim, xlim, 'r--')\n",
    "ax.set_xlabel('model prediction ($\\hat{y}$)')\n",
    "ax.set_ylabel('measurement ($y$)')\n",
    "ax.set_title(f'(d) performance ($R^2$={Rsq:.3})');\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Abeta_GE_fitting.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
